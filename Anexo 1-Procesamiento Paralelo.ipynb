{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Anexo 1\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Como es conocido las redes convolucionales contienen dentro de arquitectura procesos computing intensive, principalmente por la cantidad de operaciones matriciales que se realizan por ejemplo en la misma operación de convolución que les da el nombre. Es por esto que para dar soporte al crecimiento de DeepLearning han aparecido librerías como TensorFlow sobre ella Keras para dar soporte a esta capacidad de computo, principalmente sobre GPU.Como aprendizaje extra, motivado por mis propios intereses, se apunto a buscar soluciones que permitieran la paralelización de estas operaciones. Asociado a lo anterior y motivado por la posibilidad de usar, por periodos de tiempos, una maquina del tipo **p2.8xlarge AWS(Amazon Web Service) que tiene 8 tarjetas GPU NVidia K80**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Una ejecución de un modelo modelo que fue paralelizado lo podemos ver a continuación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![alt text](multi_GPU.png  \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Sobre estas maquinas se uso una de las tres maneras en que se puede paralelizar una red convolucional que son:\n",
    "\n",
    "\n",
    "1.\tIntra-layer parallelism: Busca paralizar las operaciones, como las multiplicaciones entre matrices por ejemplo en el ajuste del gradiente, entre capas de la red.\n",
    "2.\t Data parallelism : Busca que distintos batches del dataset de entrenamiento se procesen en GPU distintas.\n",
    "3.\t Model parallelism: Estrategia mas avanzada, busca que diferentes capas del modelo se ejecuten(sus operaciones en paralelo)  en diferentes GPU. Donde cada GPU es un nodo en el pipeline, analogía a al pipeline de procesamiento en un procesador.\n",
    "\n",
    "Para este caso se trabajo con la estrategia 2, que debe tener la consideración que la relación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$ \\frac{\\frac{datos-de-entrenamiento}{batches}}{Nº GPU`s} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Para lograr este paralelismo se uso el código del siguiente repositorio:\n",
    "\n",
    "~~~python\n",
    "https://github.com/kuza55/keras-extras/blob/master/utils/multi_gpu.py\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "En cada notebook, se debe instanciar el código en formato de librería: \n",
    "\n",
    "~~~python\n",
    "from utils.multi_gpu import make_parallel\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Dentro del código de los ejercicios se encontrará la siguiente : \n",
    "~~~python\n",
    "model = make_parallel(model, 8)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Que permite cambiar la ejecución del modelo, de una ejecución en single GPU a una que usa todas las tarjetas GPU, **esto en la actual versión de Keras no una funcionalidad disponible.**\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
