{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#librerias Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "from keras.layers import LSTM, GRU\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from utils.multi_gpu import make_parallel\n",
    "from dataset.dataset import leer\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1 CNNs en CIFAR10\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "En esta seccion, experimentaremos con redes convolucionales, conocidas como CNNs o ConvNets. Para ello y con el fin de comparar con los resultados obtenidos por redes FF, reutilizaremos el dataset CIFAR10 utilizado en la tarea anterior. Si no dispone ya del dataset en su maquina, por favor siga a las instrucciones de descarga entregadas en la tarea anterior. **Nota: Para esta actividad es bastante aconsejable entrenar las redes usando una GPU, ya que de otro modo los tiempos de entrenamiento son largos[1].**\n",
    "\n",
    "En la imagen que vemos a continuación podemos hacernos una idea de cómo funciona una una red convolucional, con capas convolucionales, capas de pooling y capas full conectadas finales(post Flaten):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![alt text](convnet.jpg  \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**[1]** Respecto al uso de GPU, para las experiencia se fue mas allá de los solicitado y se preparo un ambiente de ejecución paralelo en múltiples GPU, para mas detalles de este proceso ver Anexo 1-Procesamiento Paralelo. Podemos ver todas las GPU’s disponibles con el comando de Nvidia:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 16 00:41:15 2017       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 0000:00:17.0     Off |                    0 |\n",
      "| N/A   62C    P0    60W / 149W |      0MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla K80           Off  | 0000:00:18.0     Off |                    0 |\n",
      "| N/A   50C    P0    71W / 149W |      0MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla K80           Off  | 0000:00:19.0     Off |                    0 |\n",
      "| N/A   64C    P0    61W / 149W |      0MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla K80           Off  | 0000:00:1A.0     Off |                    0 |\n",
      "| N/A   52C    P0    70W / 149W |      0MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla K80           Off  | 0000:00:1B.0     Off |                    0 |\n",
      "| N/A   58C    P0    61W / 149W |      0MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla K80           Off  | 0000:00:1C.0     Off |                    0 |\n",
      "| N/A   48C    P0    73W / 149W |      0MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla K80           Off  | 0000:00:1D.0     Off |                    0 |\n",
      "| N/A   55C    P0    60W / 149W |      0MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla K80           Off  | 0000:00:1E.0     Off |                    0 |\n",
      "| N/A   47C    P0    73W / 149W |      0MiB / 11439MiB |     44%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID  Type  Process name                               Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Objetivo\n",
    "---\n",
    "\n",
    "\n",
    "**(a)** Prepare subconjuntos de entrenamiento, validacion y pruebas identicos a los que utilizo en el ultimo ıtem de la tarea 1. Normalice las imagenes de entrenamiento y pruebas, dividiendo las intensidades originales de pixel en cada canal por 255. Es importante recordar que en la tarea1 representamos las imagenes como un vector unidimensional. Por lo tanto, antes de trabajar con CNNs sera necesario recuperar la forma original de las imagenes. Ademas, si desea trabajar con el orden de las dimensiones denominado ’tf’ (por defecto para TensorFlow†) debera hacer realizar la transposicion correspondiente.\n",
    "Finalmente, genere una representacion adecuada de las salidas deseadas de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.5 s, sys: 859 ms, total: 2.36 s\n",
      "Wall time: 2.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "URL='data/'\n",
    "Xtr,Ytr,Xt,Yt,Xv,Yv = leer(URL)\n",
    "#Datos de entrenamiento\n",
    "X_train = Xtr.reshape((Xtr.shape[0],32,32,3))\n",
    "X_train = X_train.transpose([0, 3, 2, 1]) \n",
    "Y_train = to_categorical(Ytr, 10)\n",
    "#Datos de Test\n",
    "X_test  = Xt.reshape((Xt.shape[0],32,32,3))\n",
    "X_test  = X_test.transpose([0, 3, 2, 1])\n",
    "Y_test  = to_categorical(Yt, 10)\n",
    "#Datos de Validación\n",
    "X_val   = Xv.reshape((Xv.shape[0],32,32,3))\n",
    "X_val   = X_val.transpose([0, 3, 2, 1])\n",
    "Y_val   = to_categorical(Yv, 10)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test  = X_test.astype('float32')\n",
    "X_val   = X_val.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n",
      "(10000, 3, 32, 32)\n",
      "(50000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (Y_train.shape)\n",
    "print (Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_size, n_channels, n_rows, n_cols = X_train.shape\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "**(b)** Defina una CNN con arquitectura **C × P × C × P × F × F** . Para ambas capas convolucionales utilice 64 filtros de 3 × 3 y funciones de activaci ́on ReLu. Para las capas de pooling utilice filtros de 2 × 2 con stride 2. Para la capa MLP escondida use 512 neuronas. Genere un esquema lo mas compacto posible que muestre los cambios de forma (dimensionalidad) que experimenta un patron de entrada a medida que se ejecuta un forward-pass y el numero de parametros de cada capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 32, 32)        1792      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 16, 16)        36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 8, 8)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,141,514\n",
      "Trainable params: 2,141,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(64, (3, 3), padding='same', input_shape=(n_channels, n_rows, n_cols)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
